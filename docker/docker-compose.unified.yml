# Argus Unified — single container with agent + web UI
#
# Usage:
#   cp .env.example .env   # fill in your values
#   docker compose -f docker/docker-compose.unified.yml up -d
#
# Required env vars:
#   ARGUS_LLM_API_KEY     — your LLM API key (OpenAI, Anthropic, or Gemini)
#
# Optional env vars:
#   ARGUS_LLM_PROVIDER    — openai (default), anthropic, gemini
#   ARGUS_LLM_MODEL       — gpt-4o (default), or any model your provider supports
#   ARGUS_PUBLIC_URL      — set when accessing from a remote host, e.g. http://192.168.1.50:7600
#                           auto-rewrites Next.js URLs and CORS origins
#   ARGUS_CORS_ORIGINS    — custom CORS origins (auto-set when ARGUS_PUBLIC_URL is used)

services:
  argus:
    image: ghcr.io/precious112/argus:latest
    build:
      context: ..
      dockerfile: Dockerfile.unified
    ports:
      - "7600:7600"
      - "3000:3000"
    volumes:
      # Host system access (read-only)
      - /var/log:/host/var/log:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      # Docker API access
      - /var/run/docker.sock:/var/run/docker.sock
      # Persistent data
      - argus_data:/data
    pid: "host"
    privileged: true
    env_file:
      - path: ../.env
        required: false
    environment:
      - ARGUS_MODE=${ARGUS_MODE:-full}
      - ARGUS_HOST_ROOT=/host
      - ARGUS_DEBUG=${ARGUS_DEBUG:-false}
      - ARGUS_LLM__PROVIDER=${ARGUS_LLM_PROVIDER:-openai}
      - ARGUS_LLM__API_KEY=${ARGUS_LLM_API_KEY:-}
      - ARGUS_LLM__MODEL=${ARGUS_LLM_MODEL:-gpt-4o}
      - ARGUS_PUBLIC_URL=${ARGUS_PUBLIC_URL:-}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7600/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    restart: unless-stopped

volumes:
  argus_data:
